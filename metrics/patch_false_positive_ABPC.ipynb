{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cec653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_area_between_curves(morf_curve, lerf_curve):\n",
    "    \"\"\"\n",
    "    Compute the area between the LeRF and MoRF curves using the trapezoidal rule. In the literature, we divide\n",
    "    the area by the number of steps to normalize it.\n",
    "    \"\"\"\n",
    "    # Ensure the curves are of the same length\n",
    "    assert len(morf_curve) == len(lerf_curve), \"Curves must be of the same length\"\n",
    "\n",
    "    # Compute the area using the trapezoidal rule\n",
    "    area = 0.0\n",
    "    for i in range(1, len(morf_curve)):\n",
    "        area += 0.5 * ((lerf_curve[i] - morf_curve[i]) + (lerf_curve[i-1] - morf_curve[i-1]))\n",
    "    return area / len(morf_curve)\n",
    "\n",
    "\n",
    "def compute_aopc(morf_curve):\n",
    "    # Compute the Area Over the Perturbation Curve (AOPC)\n",
    "    reference = morf_curve[0]\n",
    "\n",
    "    area = 0.0\n",
    "    for i in range(1, len(morf_curve)):\n",
    "        area += 0.5 * ((reference - morf_curve[i]) + (reference - morf_curve[i-1]))\n",
    "    return area / len(morf_curve)\n",
    "\n",
    "def normalized_abpc(morf_curve, lerf_curve):\n",
    "    abpc = compute_area_between_curves(morf_curve, lerf_curve)\n",
    "    range = max(lerf_curve) - min(morf_curve)\n",
    "    return abpc / range\n",
    "\n",
    "def normalized_aopc(morf_curve):\n",
    "    aopc = compute_aopc(morf_curve)\n",
    "    range = max(morf_curve) - min(morf_curve)\n",
    "    return aopc / range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124ae5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target] group='ABPC-volumes', sv_type='FCC-organs', agg='false_positive_aggregation': 1 runs\n",
      "\n",
      "Run o01qjx5z | points=400 | source=signed_existing\n",
      "  ABPC_area : old = -0.00016442  -> new = 0.00016442\n",
      "  AOPC      : old = 0.00007131  -> new = 0.00023573\n",
      "  norm_ABPC : old = -1.4364  -> new = 0.5849\n",
      "  norm_AOPC : old = 0.6230  -> new = 0.8385\n",
      "\n",
      "Run o01qjx5z | points=400 | source=signed_existing\n",
      "  ABPC_area : old = -0.00016442  -> new = 0.00016442\n",
      "  AOPC      : old = 0.00007131  -> new = 0.00023573\n",
      "  norm_ABPC : old = -1.4364  -> new = 0.5849\n",
      "  norm_AOPC : old = 0.6230  -> new = 0.8385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/giulio/Desktop/tesi/ssh/XAI-AUTOMI-seg/metrics/wandb/run-20250913_120645-o01qjx5z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/giuliosichili/automi/runs/o01qjx5z' target=\"_blank\">wandering-yogurt-491</a></strong> to <a href='https://wandb.ai/giuliosichili/automi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/giuliosichili/automi' target=\"_blank\">https://wandb.ai/giuliosichili/automi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/giuliosichili/automi/runs/o01qjx5z' target=\"_blank\">https://wandb.ai/giuliosichili/automi/runs/o01qjx5z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ABPC_area</td><td>0.00016</td></tr><tr><td>ABPC_area_prev</td><td>-0.00016</td></tr><tr><td>AOPC</td><td>0.00024</td></tr><tr><td>AOPC_prev</td><td>7e-05</td></tr><tr><td>LeRF</td><td>-0.0001</td></tr><tr><td>LeRF_cache_hit_ratio_percent</td><td>21</td></tr><tr><td>LeRF_inference_time_sec</td><td>4.324</td></tr><tr><td>LeRF_volume_removed_mm3</td><td>5206010.77755</td></tr><tr><td>LeRF_volume_removed_pct</td><td>2.25082</td></tr><tr><td>LeRF_volume_removed_voxels</td><td>758939</td></tr><tr><td>MoRF</td><td>-0.0001</td></tr><tr><td>MoRF_cache_hit_ratio_percent</td><td>21</td></tr><tr><td>MoRF_inference_time_sec</td><td>4.39181</td></tr><tr><td>MoRF_volume_removed_mm3</td><td>5206010.77755</td></tr><tr><td>MoRF_volume_removed_pct</td><td>2.25082</td></tr><tr><td>MoRF_volume_removed_voxels</td><td>758939</td></tr><tr><td>norm_ABPC</td><td>0.58485</td></tr><tr><td>norm_ABPC_prev</td><td>-1.43635</td></tr><tr><td>norm_AOPC</td><td>0.83852</td></tr><tr><td>norm_AOPC_prev</td><td>0.62298</td></tr><tr><td>num_supervoxels</td><td>399</td></tr><tr><td>signed_LeRF</td><td>-0.0001</td></tr><tr><td>signed_MoRF</td><td>-0.0001</td></tr><tr><td>signed_curves</td><td>True</td></tr><tr><td>signed_metrics_refreshed</td><td>True</td></tr><tr><td>signed_metrics_source</td><td>signed_existing</td></tr><tr><td>supervoxels_perturbed</td><td>399</td></tr><tr><td>total_volume_mm3</td><td>231293539.3125</td></tr><tr><td>total_volume_voxels</td><td>33718272</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-yogurt-491</strong> at: <a href='https://wandb.ai/giuliosichili/automi/runs/o01qjx5z' target=\"_blank\">https://wandb.ai/giuliosichili/automi/runs/o01qjx5z</a><br> View project at: <a href='https://wandb.ai/giuliosichili/automi' target=\"_blank\">https://wandb.ai/giuliosichili/automi</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250913_120645-o01qjx5z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Candidate runs: 1 | Updated (or would update in DRY_RUN): 1 | Skipped: 0 | DRY_RUN=False | METRICS_ONLY=True | VERBOSE=True\n"
     ]
    }
   ],
   "source": [
    "# patch_switch_signed_curves.py\n",
    "# Append swapped/signed curves as `signed_MoRF` / `signed_LeRF` at the same supervoxels_perturbed x,\n",
    "# and update summary metrics accordingly. Verbose and dry-run by default.\n",
    "\n",
    "import os\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "# ===== USER CONFIG =====\n",
    "ENTITY = \"giuliosichili\"\n",
    "PROJECT = \"automi\"\n",
    "GROUP   = \"ABPC-volumes\"\n",
    "\n",
    "TARGET_SV_TYPE = \"FCC-organs\"\n",
    "TARGET_AGG     = \"false_positive_aggregation\"\n",
    "TARGET_VOLUME_CODES = [\"00044\"]\n",
    "\n",
    "X_KEY     = \"supervoxels_perturbed\"   # custom x-axis used during logging\n",
    "PAGE_SIZE = 512\n",
    "\n",
    "DRY_RUN   = False   # << SAFE DEFAULT: ONLY PRINT, NO WRITES >>\n",
    "VERBOSE   = True   # << PRINT per-run details >>\n",
    "# New: only recompute scalar metrics, do NOT append new signed curves\n",
    "RECOMPUTE_METRICS_ONLY = True\n",
    "# =======================\n",
    "\n",
    "# Externally provided functions must exist in your environment:\n",
    "#   compute_area_between_curves(morf_curve, lerf_curve)\n",
    "#   compute_aopc(morf_curve)\n",
    "#   normalized_abpc(morf_curve, lerf_curve)\n",
    "#   normalized_aopc(morf_curve)\n",
    "\n",
    "def _fmt(x: Optional[float], fixed4: bool = False) -> str:\n",
    "    if x is None:\n",
    "        return \"None\"\n",
    "    try:\n",
    "        xf = float(x)\n",
    "        if np.isnan(xf):\n",
    "            return \"nan\"\n",
    "        return f\"{xf:.4f}\" if fixed4 else f\"{xf:.8f}\"\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "def fetch_target_runs(api: wandb.Api) -> List[wandb.apis.public.Run]:\n",
    "    \"\"\"Find FCC-organs + false_positive_aggregation runs inside GROUP.\"\"\"\n",
    "    path = f\"{ENTITY}/{PROJECT}\"\n",
    "    filt = {\n",
    "        \"config.group\": {\"$eq\": GROUP},\n",
    "        \"config.supervoxel_type\": {\"$eq\": TARGET_SV_TYPE},\n",
    "        \"config.aggregation_function\": {\"$eq\": TARGET_AGG},\n",
    "        \"config.volume_code\": {\"$in\": TARGET_VOLUME_CODES},\n",
    "    }\n",
    "    return list(api.runs(path, filters=filt))\n",
    "\n",
    "def collect_curves_with_x_and_last_step(run: wandb.apis.public.Run) -> Tuple[np.ndarray, np.ndarray, np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Build MoRF/LeRF arrays aligned on the custom x-axis (supervoxels_perturbed).\n",
    "    Returns (morf, lerf, x_sorted, last_step_seen).\n",
    "    \"\"\"\n",
    "    morf_map: Dict[int, float] = {}\n",
    "    lerf_map: Dict[int, float] = {}\n",
    "    last_step_seen = -1\n",
    "\n",
    "    for row in run.scan_history(page_size=PAGE_SIZE):\n",
    "        step = row.get(\"_step\", row.get(\"step\"))\n",
    "        if step is None:\n",
    "            continue\n",
    "        try:\n",
    "            step = int(step)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if step > last_step_seen:\n",
    "            last_step_seen = step\n",
    "\n",
    "        # x-axis (prefer supervoxels_perturbed; fallback to step)\n",
    "        x = row.get(X_KEY, step)\n",
    "        try:\n",
    "            x = int(x)\n",
    "        except Exception:\n",
    "            try:\n",
    "                x = int(float(x))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        m = row.get(\"MoRF\", None)\n",
    "        l = row.get(\"LeRF\", None)\n",
    "        if m is not None:\n",
    "            try:\n",
    "                morf_map[x] = float(m)\n",
    "            except Exception:\n",
    "                pass\n",
    "        if l is not None:\n",
    "            try:\n",
    "                lerf_map[x] = float(l)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    common_x = sorted(set(morf_map.keys()) & set(lerf_map.keys()))\n",
    "    if not common_x:\n",
    "        return np.array([]), np.array([]), np.array([]), last_step_seen\n",
    "\n",
    "    morf = np.array([morf_map[i] for i in common_x], dtype=float)\n",
    "    lerf = np.array([lerf_map[i] for i in common_x], dtype=float)\n",
    "    xs   = np.array(common_x, dtype=int)\n",
    "    return morf, lerf, xs, last_step_seen\n",
    "\n",
    "def collect_signed_curves_if_present(run: wandb.apis.public.Run) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"If signed_MoRF / signed_LeRF already logged, return them aligned on X_KEY. Else empty arrays.\"\"\"\n",
    "    morf_map: Dict[int, float] = {}\n",
    "    lerf_map: Dict[int, float] = {}\n",
    "    for row in run.scan_history(page_size=PAGE_SIZE):\n",
    "        x = row.get(X_KEY, row.get(\"_step\", row.get(\"step\")))\n",
    "        try:\n",
    "            x = int(x)\n",
    "        except Exception:\n",
    "            try:\n",
    "                x = int(float(x))\n",
    "            except Exception:\n",
    "                continue\n",
    "        sm = row.get(\"signed_MoRF\")\n",
    "        sl = row.get(\"signed_LeRF\")\n",
    "        if sm is not None:\n",
    "            try:\n",
    "                morf_map[x] = float(sm)\n",
    "            except Exception:\n",
    "                pass\n",
    "        if sl is not None:\n",
    "            try:\n",
    "                lerf_map[x] = float(sl)\n",
    "            except Exception:\n",
    "                pass\n",
    "    common_x = sorted(set(morf_map.keys()) & set(lerf_map.keys()))\n",
    "    if not common_x:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "    morf = np.array([morf_map[i] for i in common_x], dtype=float)\n",
    "    lerf = np.array([lerf_map[i] for i in common_x], dtype=float)\n",
    "    xs   = np.array(common_x, dtype=int)\n",
    "    return morf, lerf, xs\n",
    "\n",
    "def recompute_from_corrected(morf_fixed: np.ndarray, lerf_fixed: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Compute corrected metrics from corrected curves using user's functions.\n",
    "    Adds guards in case normalization denominators become zero.\n",
    "    \"\"\"\n",
    "    out: Dict[str, float] = {}\n",
    "    out[\"ABPC_area\"] = float(compute_area_between_curves(morf_fixed, lerf_fixed))\n",
    "    out[\"AOPC\"]      = float(compute_aopc(morf_fixed))\n",
    "    try:\n",
    "        out[\"norm_ABPC\"] = float(normalized_abpc(morf_fixed, lerf_fixed))\n",
    "    except ZeroDivisionError:\n",
    "        out[\"norm_ABPC\"] = float('nan')\n",
    "    try:\n",
    "        out[\"norm_AOPC\"] = float(normalized_aopc(morf_fixed))\n",
    "    except ZeroDivisionError:\n",
    "        out[\"norm_AOPC\"] = float('nan')\n",
    "    return out\n",
    "\n",
    "def old_summary_metrics(run: wandb.apis.public.Run) -> Dict[str, Optional[float]]:\n",
    "    s = run.summary or {}\n",
    "    def g(k):\n",
    "        v = s.get(k)\n",
    "        try:\n",
    "            return float(v) if v is not None else None\n",
    "        except Exception:\n",
    "            return None\n",
    "    return {\n",
    "        \"ABPC_area\": g(\"ABPC_area\"),\n",
    "        \"AOPC\": g(\"AOPC\"),\n",
    "        \"norm_ABPC\": g(\"norm_ABPC\"),\n",
    "        \"norm_AOPC\": g(\"norm_AOPC\"),\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    api = wandb.Api()\n",
    "    runs = fetch_target_runs(api)\n",
    "    print(f\"[target] group='{GROUP}', sv_type='{TARGET_SV_TYPE}', agg='{TARGET_AGG}': {len(runs)} runs\")\n",
    "\n",
    "    patched, skipped = 0, 0\n",
    "    for run in runs:\n",
    "        try:\n",
    "            xs = None  # ensure defined\n",
    "            last_step = -1\n",
    "            # Prefer already signed curves if present when metrics-only\n",
    "            signed_morf, signed_lerf, signed_x = collect_signed_curves_if_present(run) if RECOMPUTE_METRICS_ONLY else (np.array([]), np.array([]), np.array([]))\n",
    "            if RECOMPUTE_METRICS_ONLY and signed_morf.size > 1 and signed_lerf.size > 1:\n",
    "                source = \"signed_existing\"\n",
    "                morf_fixed, lerf_fixed = signed_morf, signed_lerf\n",
    "                xs = signed_x\n",
    "            else:\n",
    "                morf, lerf, xs_local, last_step_local = collect_curves_with_x_and_last_step(run)\n",
    "                xs = xs_local\n",
    "                last_step = last_step_local\n",
    "                if morf.size == 0 or lerf.size == 0:\n",
    "                    if VERBOSE:\n",
    "                        print(f\"- {run.id} SKIP: no aligned MoRF/LeRF on '{X_KEY}'\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                # swap to get corrected\n",
    "                morf_fixed, lerf_fixed = lerf.copy(), morf.copy()\n",
    "                source = \"swapped_from_raw\"\n",
    "\n",
    "            new_metrics = recompute_from_corrected(morf_fixed, lerf_fixed)\n",
    "            old_metrics = old_summary_metrics(run)\n",
    "\n",
    "            if VERBOSE:\n",
    "                print(f\"\\nRun {run.id} | points={len(morf_fixed)} | source={source}\")\n",
    "                print(\"  ABPC_area : old =\", _fmt(old_metrics[\"ABPC_area\"], fixed4=False), \" -> new =\", _fmt(new_metrics[\"ABPC_area\"], fixed4=False))\n",
    "                print(\"  AOPC      : old =\", _fmt(old_metrics[\"AOPC\"],      fixed4=False), \" -> new =\", _fmt(new_metrics[\"AOPC\"],      fixed4=False))\n",
    "                print(\"  norm_ABPC : old =\", _fmt(old_metrics[\"norm_ABPC\"], fixed4=True),  \" -> new =\", _fmt(new_metrics[\"norm_ABPC\"], fixed4=True))\n",
    "                print(\"  norm_AOPC : old =\", _fmt(old_metrics[\"norm_AOPC\"], fixed4=True),  \" -> new =\", _fmt(new_metrics[\"norm_AOPC\"], fixed4=True))\n",
    "\n",
    "            if DRY_RUN:\n",
    "                patched += 1\n",
    "                continue\n",
    "\n",
    "            os.environ[\"WANDB_RESUME\"] = \"allow\"\n",
    "            os.environ[\"WANDB_RUN_ID\"] = run.id\n",
    "            session = wandb.init(entity=run.entity, project=run.project, id=run.id, resume=\"allow\")\n",
    "\n",
    "            if not RECOMPUTE_METRICS_ONLY:\n",
    "                # we must have last_step; if not, collect again\n",
    "                if last_step < 0:\n",
    "                    _, _, _, last_step = collect_curves_with_x_and_last_step(run)\n",
    "                start_step = int(last_step) + 1\n",
    "                for i in range(len(morf_fixed)):\n",
    "                    payload = {\n",
    "                        \"signed_MoRF\": float(morf_fixed[i]),\n",
    "                        \"signed_LeRF\": float(lerf_fixed[i]),\n",
    "                        X_KEY: int(xs[i]) if xs is not None and i < len(xs) else i,\n",
    "                    }\n",
    "                    wandb.log(payload, step=start_step + i)\n",
    "\n",
    "            # Update summary metrics\n",
    "            session.summary.update({\n",
    "                \"ABPC_area_prev\": old_metrics[\"ABPC_area\"],\n",
    "                \"AOPC_prev\": old_metrics[\"AOPC\"],\n",
    "                \"norm_ABPC_prev\": old_metrics[\"norm_ABPC\"],\n",
    "                \"norm_AOPC_prev\": old_metrics[\"norm_AOPC\"],\n",
    "                **new_metrics,\n",
    "                \"signed_curves\": True,\n",
    "                \"signed_metrics_refreshed\": RECOMPUTE_METRICS_ONLY,\n",
    "                \"signed_metrics_source\": source,\n",
    "            })\n",
    "\n",
    "            session.finish()\n",
    "            patched += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            if VERBOSE:\n",
    "                print(f\"- {run.id} ERROR: {e}\")\n",
    "            skipped += 1\n",
    "\n",
    "    print(f\"\\nDone. Candidate runs: {len(runs)} | Updated (or would update in DRY_RUN): {patched} | Skipped: {skipped} | DRY_RUN={DRY_RUN} | METRICS_ONLY={RECOMPUTE_METRICS_ONLY} | VERBOSE={VERBOSE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df96e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ABPC_area</td><td>-0.00016</td></tr><tr><td>AOPC</td><td>7e-05</td></tr><tr><td>LeRF</td><td>-0.0001</td></tr><tr><td>LeRF_cache_hit_ratio_percent</td><td>21</td></tr><tr><td>LeRF_inference_time_sec</td><td>4.324</td></tr><tr><td>LeRF_volume_removed_mm3</td><td>5206010.77755</td></tr><tr><td>LeRF_volume_removed_pct</td><td>2.25082</td></tr><tr><td>LeRF_volume_removed_voxels</td><td>758939</td></tr><tr><td>MoRF</td><td>-0.0001</td></tr><tr><td>MoRF_cache_hit_ratio_percent</td><td>21</td></tr><tr><td>MoRF_inference_time_sec</td><td>4.39181</td></tr><tr><td>MoRF_volume_removed_mm3</td><td>5206010.77755</td></tr><tr><td>MoRF_volume_removed_pct</td><td>2.25082</td></tr><tr><td>MoRF_volume_removed_voxels</td><td>758939</td></tr><tr><td>norm_ABPC</td><td>-1.43635</td></tr><tr><td>norm_AOPC</td><td>0.62298</td></tr><tr><td>num_supervoxels</td><td>399</td></tr><tr><td>signed_LeRF</td><td>-0.0001</td></tr><tr><td>signed_MoRF</td><td>-0.0001</td></tr><tr><td>supervoxels_perturbed</td><td>399</td></tr><tr><td>total_volume_mm3</td><td>231293539.3125</td></tr><tr><td>total_volume_voxels</td><td>33718272</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-yogurt-491</strong> at: <a href='https://wandb.ai/giuliosichili/automi/runs/o01qjx5z' target=\"_blank\">https://wandb.ai/giuliosichili/automi/runs/o01qjx5z</a><br> View project at: <a href='https://wandb.ai/giuliosichili/automi' target=\"_blank\">https://wandb.ai/giuliosichili/automi</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250913_120357-o01qjx5z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

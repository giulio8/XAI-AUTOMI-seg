{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b9580c",
   "metadata": {},
   "source": [
    "# 1. Import Packages for the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f23939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages for later use\n",
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb387d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13843711",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "IN_COLAB = not IN_KAGGLE and os.path.exists('/content')\n",
    "IN_DEIB = not IN_KAGGLE and not IN_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d999c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_DEIB:\n",
    "    !pip install nnunetv2\n",
    "    !pip install captum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4e820",
   "metadata": {},
   "source": [
    "# 2. Mount the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf7c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_dir: /workspace/output\n"
     ]
    }
   ],
   "source": [
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Google Colab\n",
    "    # for colab users only - mounting the drive\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount = True)\n",
    "\n",
    "    drive_dir = \"/content/drive/My Drive\"\n",
    "    mount_dir = join(drive_dir, \"tesi\", \"automi\")\n",
    "    base_dir = os.getcwd()\n",
    "elif IN_KAGGLE:\n",
    "    # Kaggle\n",
    "    mount_dir = \"/kaggle/input/automi-seg\"\n",
    "    base_dir = os.getcwd()\n",
    "    print(base_dir)\n",
    "    !ls '/kaggle/input'\n",
    "    !cd \"/kaggle/input/automi-seg\" ; ls\n",
    "else:\n",
    "    mount_dir = \"/workspace/data\"\n",
    "    base_dir = \"/workspace/output\"\n",
    "    os.chdir(base_dir)\n",
    "    print(\"base_dir:\", base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348ee98a",
   "metadata": {},
   "source": [
    "# 3. Setting up nnU-Nets folder structure and environment variables\n",
    "nnUnet expects a certain folder structure and environment variables.\n",
    "\n",
    "Roughly they tell nnUnet:\n",
    "1. Where to look for stuff\n",
    "2. Where to put stuff\n",
    "\n",
    "For more information about this please check: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be999e",
   "metadata": {},
   "source": [
    "## 3.1 Set environment Variables and creating folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf90c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw: /workspace/data/nnunet_raw\n",
      "nnUNet_results: /workspace/data/results\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# ðŸ“¦ SETUP nnUNet ENVIRONMENT\n",
    "# ===========================\n",
    "\n",
    "# Definisci i path da settare\n",
    "path_dict = {\n",
    "    \"nnUNet_raw\": join(mount_dir, \"nnunet_raw\"),\n",
    "    \"nnUNet_preprocessed\": join(mount_dir, \"preprocessed_files\"),#\"nnUNet_preprocessed\"),\n",
    "    \"nnUNet_results\": join(mount_dir, \"results\"),#\"nnUNet_results\"),\n",
    "    # \"RAW_DATA_PATH\": join(mount_dir, \"RawData\"),  # Facoltativo, se ti serve salvare zips\n",
    "}\n",
    "\n",
    "# Scrivi i path nelle variabili di ambiente, che vengono lette dal modulo paths di nnunetv2\n",
    "for env_var, path in path_dict.items():\n",
    "    os.environ[env_var] = path\n",
    "\n",
    "from nnunetv2.paths import nnUNet_results, nnUNet_raw\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    if nnUNet_raw == None:\n",
    "        nnUNet_raw = \"/kaggle/input/nnunet_raw\"\n",
    "    if nnUNet_results == None:\n",
    "        nnUNet_results = \"/kaggle/input/results\"\n",
    "    # Kaggle has some very unconsistent behaviors in dataset mounting...\n",
    "    #nnUNet_raw = \"/kaggle/input/automi-seg/nnunet_raw\"\n",
    "    #nnUNet_results = \"/kaggle/input/automi-seg/results\"\n",
    "    \n",
    "print(\"nnUNet_raw:\", nnUNet_raw)\n",
    "print(\"nnUNet_results:\", nnUNet_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33ef2d",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622657ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all volumes of fold 0 test set\n",
    "volume_codes = [\"00004\", \"00005\", \"00024\", \"00027\", \"00029\", \"00034\", \"00039\", \"00044\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf0ddbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume 00004:\n",
      "CT shape: (512, 512, 221)\n",
      "Organ shape: (512, 512, 221)\n",
      "Spacing: (1.3671875, 1.3671875, 5.0)\n",
      "Organ spacing: (1.3671875, 1.3671875, 5.0)\n",
      "Volume 00005:\n",
      "CT shape: (512, 512, 219)\n",
      "Organ shape: (512, 512, 219)\n",
      "Spacing: (1.171875, 1.171875, 5.0)\n",
      "Organ spacing: (1.171875, 1.171875, 5.0)\n",
      "Volume 00024:\n",
      "CT shape: (512, 512, 321)\n",
      "Organ shape: (512, 512, 321)\n",
      "Spacing: (0.976562, 0.976562, 3.0)\n",
      "Organ spacing: (0.976562, 0.976562, 3.0)\n",
      "Volume 00027:\n",
      "CT shape: (512, 512, 236)\n",
      "Organ shape: (512, 512, 236)\n",
      "Spacing: (1.3671875, 1.3671875, 5.0)\n",
      "Organ spacing: (1.3671875, 1.3671875, 5.0)\n",
      "Volume 00029:\n",
      "CT shape: (512, 512, 259)\n",
      "Organ shape: (512, 512, 259)\n",
      "Spacing: (1.367188, 1.367188, 7.5)\n",
      "Organ spacing: (1.367188, 1.367188, 7.5)\n",
      "Volume 00034:\n",
      "CT shape: (512, 512, 249)\n",
      "Organ shape: (512, 512, 249)\n",
      "Spacing: (1.171875, 1.171875, 5.0)\n",
      "Organ spacing: (1.171875, 1.171875, 5.0)\n",
      "Volume 00039:\n",
      "CT shape: (512, 512, 283)\n",
      "Organ shape: (512, 512, 283)\n",
      "Spacing: (1.171875, 1.171875, 5.0)\n",
      "Organ spacing: (1.171875, 1.171875, 5.0)\n",
      "Volume 00044:\n",
      "CT shape: (512, 512, 232)\n",
      "Organ shape: (512, 512, 232)\n",
      "Spacing: (1.1712891, 1.1712891, 5.0)\n",
      "Organ spacing: (1.1712891, 1.1712891, 5.0)\n"
     ]
    }
   ],
   "source": [
    "ct_img_paths = {}\n",
    "organ_map_paths = {}\n",
    "\n",
    "for volume_code in volume_codes:\n",
    "    if IN_KAGGLE:\n",
    "        ct_img_paths[volume_code] = join(nnUNet_raw, \"imagesTr\", f\"AUTOMI_{volume_code}_0000.nii\")\n",
    "        organ_map_paths[volume_code] = join(nnUNet_raw, \"total_segmentator_structures\", f\"AUTOMI_{volume_code}_0000\", \"mask_mask_add_input_20_total_segmentator.nii\")\n",
    "    else:\n",
    "        ct_img_paths[volume_code] = join(nnUNet_raw, \"imagesTr\", f\"AUTOMI_{volume_code}_0000.nii.gz\")\n",
    "        organ_map_paths[volume_code] = join(nnUNet_raw, \"total_segmentator_structures\", f\"AUTOMI_{volume_code}_0000\", \"mask_mask_add_input_20_total_segmentator.nii.gz\")\n",
    "    ct_img = nib.load(ct_img_paths[volume_code])\n",
    "    organ_map = nib.load(organ_map_paths[volume_code])\n",
    "    print(f\"Volume {volume_code}:\")\n",
    "    print(\"CT shape:\", ct_img.shape)\n",
    "    print(\"Organ shape:\", organ_map.shape)\n",
    "    print(\"Spacing:\", ct_img.header.get_zooms())\n",
    "    print(\"Organ spacing:\", organ_map.header.get_zooms())\n",
    "    assert np.all(ct_img.affine == organ_map.affine), \"CT and organ mask affine matrices do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868440df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affine: [[-1.17187500e+00  0.00000000e+00  0.00000000e+00  3.00000000e+02]\n",
      " [ 0.00000000e+00 -1.17187500e+00  0.00000000e+00  1.85300003e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  5.00000000e+00 -1.43419995e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "ct_img = nib.load(ct_img_paths[volume_codes[1]])\n",
    "print(\"affine:\", ct_img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea583f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "# define an utility for Nifty file saving\n",
    "def save_nifty(data: Union[np.ndarray, torch.Tensor], affine, path, dtype=np.float32):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.detach().cpu().numpy()\n",
    "    # set fixed type float32\n",
    "    data = data.astype(dtype)\n",
    "    nib.save(nib.Nifti1Image(data, affine), path)\n",
    "\n",
    "def save_nifty_binary(data: Union[np.ndarray, torch.Tensor], affine, path):\n",
    "    return save_nifty(data, affine, path, dtype=np.uint8)\n",
    "\n",
    "\n",
    "# define an utility for annoying nnunetv2 preprocessing\n",
    "def nnunetv2_default_preprocessing(ct_img_path, \n",
    "                                   predictor, \n",
    "                                   dataset_json_path,\n",
    "                                   other_volumes: Union[np.ndarray, None] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocesses the CT image and other volumes using nnunetv2's default preprocessing\n",
    "    pipeline. This function reads the CT image, applies the preprocessor, and returns\n",
    "    the preprocessed image.\n",
    "    \"\"\"\n",
    "    plans_manager = predictor.plans_manager\n",
    "    configuration_manager = predictor.configuration_manager\n",
    "    \n",
    "    preprocessor = configuration_manager.preprocessor_class(verbose=False)\n",
    "    rw = plans_manager.image_reader_writer_class()\n",
    "    if callable(rw) and not hasattr(rw, \"read_images\"):\n",
    "        rw = rw()\n",
    "    img_np, img_props = rw.read_images([str(ct_img_path)])\n",
    "    \n",
    "    preprocessed, other_volumes_preprocessed, _ = preprocessor.run_case_npy(\n",
    "        img_np, seg=other_volumes, properties=img_props,\n",
    "        plans_manager=plans_manager,\n",
    "        configuration_manager=configuration_manager,\n",
    "        dataset_json=dataset_json_path\n",
    "    )\n",
    "    if other_volumes:\n",
    "        return preprocessed, other_volumes_preprocessed\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d38b43",
   "metadata": {},
   "source": [
    "## Evaluate attribution maps using ABPC (Area Between Perturbation Curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b07e9",
   "metadata": {},
   "source": [
    "### Let's start with FCC supervoxel attribution maps, True Positive aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec90e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "attribution_map_paths = {}\n",
    "for volume_code in volume_codes:\n",
    "    attribution_map_paths[volume_code] = Path(join(volume_code, \"attribution_map.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the perturbation function\n",
    "def perturb(original_volume: torch.Tensor,\n",
    "             interpretable_input: np.ndarray,\n",
    "             feature_map: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\"\n",
    "    return the perturbed input and the perturbation map\n",
    "    \"\"\"\n",
    "    # apply the perturbation to the original volume\n",
    "    perturbed_volume = original_volume.clone()\n",
    "    perturbed_volume[feature_map > 0] = interpretable_input[feature_map > 0]\n",
    "    return perturbed_volume, perturbation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639612d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "# let's define the main block to compute one evaluation step, given the\n",
    "# original volume, the interpretable input vector, and the forward function\n",
    "def evaluate_step(original_volume: torch.Tensor,\n",
    "                  interpretable_input: np.ndarray,\n",
    "                  feature_map: torch.Tensor,\n",
    "                  forward_function: Callable):\n",
    "    # obtain perturbed output\n",
    "    perturbed_output, perturbation_map = perturb(original_volume, \n",
    "                                                 interpretable_input, \n",
    "                                                 feature_map)\n",
    "\n",
    "    # compute the forward pass with the perturbed input\n",
    "    output = forward_function(perturbed_output, perturbation_map)\n",
    "\n",
    "    return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
